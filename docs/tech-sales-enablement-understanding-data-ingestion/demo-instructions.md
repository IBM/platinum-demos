---
title: Part 3 - Customizing customers' CI/CD pipeline for IBM Concert <br/> <small> <i> Tech Sales enablement </i> </small>
layout: demo-instructions
---

<span id="top"></span>

<br/>

Click the [**Pre-requisites**](pre-requisites) tab for setup instructions.

<details markdown="1">

<summary>Introduction</summary>

<img src="images/1.png" width="800" /> <br/>

In the CI/CD pipeline, vulnerability scanning plays a critical role in ensuring that security is embedded into the software delivery process. The optimal point for conducting these scans is between **Test** and **Release**. At this stage, the code has passed functional testing, ensuring it meets quality standards. But before it is packaged and deployed, it undergoes security scrutiny.

<img src="images/2.png" width="800" /> <br/>

<inline-notification text="Each customer’s IBM Concert implementation can vary based on their environment and CI/CD workflows, which may result in different stage names or configurations. Flexibility is key to addressing customer-specific needs, while ensuring core CI/CD integration principles are maintained."></inline-notification>

<br/>

</details>

<p/>

<details markdown="1">

<summary>1 - Configure customer's pipeline</summary>

In the non-production CI/CD environment provisioned by the customer in advance of the PoV, the following changes should be performed to ensure a smooth and effective demonstration. 

<br/>

| **Action** 1.1 | If not already present, insert a secondary inner pipeline labeled **vulnerability-analysis** between **TEST** and **RELEASE** in the customer's pipeline.  |
| :--- | :--- |
|  | This can be done by utilizing the modularity of both Jenkins and Tekton to invoke a dedicated security check pipeline from within the main pipeline. <br/><br/> In Jenkins, this secondary pipeline can be set up as a downstream job, triggered from the main pipeline using the build step: <br/><br/> <code class="code-block"> stage('vulnerability-analysis') {<br/>    steps {<br/>        build job: 'vulnerability-analysis-job', wait: true <br/>    } <br/> } </code> <br/><br/> In Tekton, a similar structure can be established using Pipeline Tasks or PipelineRuns, enabling the main pipeline to invoke a separate pipeline for vulnerability scanning tasks. <br/><br/> <code class="code-block"> apiVersion: tekton.dev/v1beta1 <br/> kind: Task <br/> metadata: <br/>  name: trigger-vulnerability-analysis <br/> spec: <br/>  steps: <br/>    - name: run-vulnerability-analysis <br/>      image: gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/pullrequest-init <br/>      script: | <br/>        tkn pipeline start vulnerability-analysis-pipeline --param target-image=$(params.image) </code> |

<br/>

| **Action** 1.2 | In this new inner pipeline, labeled **vulnerability-analysis**, create the tasks outlined below.  |
| :--- | :--- |
|  | The structure of the pipeline will be as follows: <br/> <img src="images/3.png" width="600" /> <br/> • **prepare**: Download and set up the necessary IBM Concert toolkit image, along with the source code repositories and container images for all microservices in the target application, ensuring the environment is ready for further analysis. <br/> • **code-scan**: Conduct a thorough static analysis of the codebase, inspecting the application’s source code, third-party libraries, and dependencies to identify potential security vulnerabilities or weaknesses. <br/> • **image-scan**: Perform an in-depth scan of the container images used in the application to detect any security vulnerabilities or misconfigurations that could impact the integrity of the containerized environment. <br/> • **cve-scan**: Analyze the components identified in the Software Bill of Materials (SBOM) and cross-reference them against the CVE (Common Vulnerabilities and Exposures) database to identify known vulnerabilities and assess their impact on the application. |
| **Action** 1.2.1 | In the newly created **prepare** task of the **vulnerability-analysis** inner pipeline, add the necessary commands to download the IBM Concert toolkit, along with all microservice images and their corresponding source code repositories. <br/><br/> The code snippets below demonstrate the structure of the command, though the exact syntax may vary depending on the CI/CD pipeline platform being used. <br/><br/> Fetch a copy of the IBM Concert toolkit image to the local Docker server if it is not already present: <br/><br/> <code class="code-block"> docker pull --platform "linux/amd64" \ <br/>  "cp.stg.icr.io/cp/concert/toolkit/ibm-concert-toolkit:latest" </code> <br/><br/> Fetch a copy of the microservices' source code to the local file system if it is not already present: <br/><br/> <code class="code-block"> for i in "${!DEMO_APP_REPOSITORY_URL[@]}"; do <br/>    repo_url="${DEMO_APP_REPOSITORY_URL[$i]}" <br/>    <br/>    echo "$(date +'%Y-%m-%d %H:%M:%S') [INFO] Cloning the demo repository for ${repo_url}..." <br/>    if git clone "https://${repo_url}"; then <br/>      echo "$(date +'%Y-%m-%d %H:%M:%S') [INFO] Successfully cloned ${repo_folder} repository." <br/>    else <br/>      echo "$(date +'%Y-%m-%d %H:%M:%S') [ERROR] An error occurred during the code repo clone procedure for ${repo_folder}." <br/>      exit 1 <br/>    fi <br/> done </code> <br/><br/> Pull a copy of the microservices' image to the local Docker server if it is not already present: <br/><br/> <code class="code-block"> for i in "${!DEMO_APP_IMAGE_URL[@]}"; do  # Iterate over the indices, not values <br/>    service="${DEMO_APP_COMPONENT[$i]}" <br/> <br/>    # Pull image using the base image URL and image tag <br/>    docker pull "${DEMO_APP_IMAGE_URL[$i]}:${DEMO_APP_IMAGE_TAG[$i]}" <br/> <br/>    if [ $? -ne 0 ]; then <br/>        echo "$(date +'%Y-%m-%d %H:%M:%S') [ERROR] Error occurred while pulling image for $service" <br/>    fi <br/> done </code> |
| **Action** 1.2.2 | In the newly created **code-scan** task within the **vulnerability-analysis** inner pipeline, include the following commands to perform a code scan using the IBM Concert toolkit: <br/><br/> <code class="code-block"> docker run --user 0 --platform "linux/amd64" \ <br/>    --volume "$(pwd)/toolkit-data:/toolkit-data" \ <br/>    --volume "$(pwd)/$src_repo:/$src_repo" \ <br/>    --interactive \ <br/>    --env JAVA_HOME="$JAVA_HOME" \ <br/>    "cp.stg.icr.io/cp/concert/toolkit/ibm-concert-toolkit:latest" \ <br/>    bash -c code-scan --src ${src_repo} --output-file ${DEMO_APP_NAME}-${service}-${PACKAGE_SBOM_CODESCAN_OUTPUT_FILENAME_SUFFIX} </code> |
| **Action** 1.2.3 | In the newly created **image-scan** task of the **vulnerability-analysis** inner pipeline, include the following commands to perform a code scan using the IBM Concert toolkit: <br/><br/> <code class="code-block"> docker run --user 0 --platform "linux/amd64" \ <br/>    --volume "$(pwd)/toolkit-data:/toolkit-data" \ <br/>    --volume "$(pwd)/$src_repo:/$src_repo" \ <br/>    --interactive \ <br/>    --env JAVA_HOME="$JAVA_HOME" \ <br/>    "cp.stg.icr.io/cp/concert/toolkit/ibm-concert-toolkit:latest" \ <br/>    bash -c image-scan --images ${IMAGES} </code> |
| **Action** 1.2.4 | In the newly created **cve-scan** task of the **vulnerability-analysis** inner pipeline, include the following commands to perform a code scan using the IBM Concert toolkit: <br/><br/> <code class="code-block"> grype "${image}" --by-cve -o template <br/>    -t "${TEMPLATE_GRYPE_FILE}" > "${OUTPUT_DIR}/${OUTPUT_FILENAME}" </code> <br/><br/> **TEMPLATE_GRYPE_FILE** refers to the path of the Grype template that maps each Grype output to the format required by IBM Concert. <br/><br/> <code class="code-block"> CVE,Image,Package,Package Version,Package Path,Severity,Score,hasFix,Fixed Version,Description,Tag,Digest <br/> {{- $imagetag := split ":" .Source.Target.UserInput }} <br/> {{- $image := $imagetag._0 }} <br/> {{- $tag := $imagetag._1 }} <br/> {{- $digest := 0 }} <br/> {{- range .Source.Target.RepoDigests }} <br/> {{- $repodigest := split "@" . }} <br/> {{- $digest = $repodigest._1 }} <br/> {{- end }} <br/> {{- range $v := .Matches}} <br/>  {{- $hasFix := "N" }} <br/>  {{- $fixedIn := "" }} <br/>  {{- $vid := $v.Vulnerability.ID }} <br/>  {{- $pkgname := $v.Artifact.Name }} <br/>  {{- $pkgver := $v.Artifact.Version }} <br/>  {{- $sev := $v.Vulnerability.Severity }} <br/>  {{- $desc := "DESCRIPTION HERE" }} <br/>  {{- if eq .Vulnerability.Fix.State "fixed" }} <br/>    {{- $hasFix = "Y" }} <br/>    {{- $fixedIn = "Fixed in" }} <br/>    {{- range $vers := .Vulnerability.Fix.Versions }} <br/>      {{- $fixedIn = cat $fixedIn $vers }} <br/>    {{- end }} <br/>  {{- end }} <br/>  {{- $score := "0" }} <br/>  {{- range $c := .Vulnerability.Cvss }} <br/>    {{- $score = $c.Metrics.BaseScore }} <br/>  {{- end }} <br/>  {{- range $path := .Artifact.Locations }} <br/> "{{$vid}}","{{$image}}","{{$pkgname}}","{{$pkgver}}","{{$path.RealPath}}","{{$sev}}","{{$score}}","{{$hasFix}}","{{$fixedIn}}","{{$desc}}","{{$tag}}","{{$digest}}" <br/>  {{- end }} <br/> {{- end }} </code> <br/><br/> You can download this file <a href="https://github.ibm.com/ibm-concert-platinum-demos/concert-pm-utils/blob/64d2bb900519e1eacf06ca275f4f45af2d6263aa/macos/templates/grype-cve.tmpl" target="_blank" rel="noreferrer">here</a>. <br/><br/> After the creation of the first new child pipeline described above, the main CI/CD pipeline used for the Proof of Value will be structured as follows: <br/> <img src="images/4.png" width="800" /> |

<br/>

| **Action** 1.3 | Insert a secondary inner pipeline labeled **post-build-analysis** after **DEPLOY** and before **OPERATE** in the customer's pipeline. |
| :--- | :--- |
|  | As we did previously, this can be done by utilizing the modularity of both Jenkins and Tekton to invoke a separated pipeline designed to generated all concert-defined SBOMs from within the main pipeline. <br/><br/> In Jenkins, similar to the previous setup, this secondary pipeline can be configured as a downstream job, triggered from the main pipeline using the build step: <br/><br/> <code class="code-block"> stage('post-build-analysis') { <br/>    steps { <br/>        build job: 'post-build-analysis-job', wait: true <br/>    } <br/> } </code> <br/><br/> In Tekton, a similar structure can be established using Pipeline Tasks or PipelineRuns, enabling the main pipeline to invoke a separate pipeline for vulnerability scanning tasks: <br/><br/> <code class="code-block"> apiVersion: tekton.dev/v1beta1 <br/> kind: Task <br/> metadata: <br/>  name: trigger-post-build-analysis <br/> spec: <br/>  steps: <br/>    - name: run-post-build-analysis <br/>      image: gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/pullrequest-init <br/>      script: | <br/>        tkn pipeline start post-build-analysis-pipeline --param target-image=$(params.image) </code> <br/><br/> In this new inner pipeline, labeled **post-build-analysis**, create the tasks outlined below. The structure of the pipeline will be as follows: <br/> <img src="images/5.png" width="600" /> <br/> • **build-sbom**: Create a Software Bill of Materials (SBOM) for the build environment, capturing all dependencies and tools used during the build process. <br/> • **deploy-sbom**: Generate an SBOM for the deployment environment, detailing the infrastructure and configuration files involved in the deployment. <br/> • **app-definition**: Produce an SBOM outlining the application's modules, libraries, and dependencies for a comprehensive view of its components. <br/> • **data-upload**: Upload all generated SBOMs and security data to IBM Concert for analysis, tracking and validation. |
| **Action** 1.3.1 | In the newly created **build-sbom** task of the **post-build-analysis** inner pipeline, include the following commands to create the Concert-defined Build SBOM using the IBM Concert toolkit: <br/><br/> <code class="code-block"> docker pull --platform "linux/amd64" \ <br/>  "cp.stg.icr.io/cp/concert/toolkit/ibm-concert-toolkit:latest" </code> <br/><br/> For the **build-sbom** task to function properly, it requires a configuration file containing <a href="https://github.ibm.com/ibm-concert-platinum-demos/concert-pm-utils/blob/64d2bb900519e1eacf06ca275f4f45af2d6263aa/macos/templates/build-sbom-config-template.yaml" target="_blank" rel="noreferrer">this information</a>. |
| **Action** 1.3.2 | In the newly created **deploy-sbom** task of the **post-build-analysis** inner pipeline, include the following commands to create the Concert-defined Build SBOM using the IBM Concert toolkit: <br/><br/> <code class="code-block"> docker run --user 0 --platform "linux/amd64" \ <br/>      --volume "$(pwd)/toolkit-data:/toolkit-data" \ <br/>      --volume "$(pwd)/$TEMPLATES_DIR:/$TEMPLATES_DIR" \ <br/>      --volume "$(pwd)/$TMP_DIR:/$TMP_DIR" \ <br/>      --interactive \ <br/>      "cp.stg.icr.io/cp/concert/toolkit/ibm-concert-toolkit:latest" \ <br/>      bash -c "deploy-sbom --deploy-config ${OUTPUT_CONFIG_FILE}" </code> <br/><br/> For the **deploy-sbom** task to function properly, it requires a configuration file containing <a href="https://github.ibm.com/ibm-concert-platinum-demos/concert-pm-utils/blob/64d2bb900519e1eacf06ca275f4f45af2d6263aa/macos/templates/build-sbom-config-template.yaml" target="_blank" rel="noreferrer">this information</a>. |
| **Action** 1.3.3 | In the newly created **app-definition** task of the **post-build-analysis** inner pipeline, include the following commands to create the Concert-defined Build SBOM using the IBM Concert toolkit: <br/><br/> <code class="code-block"> docker run --user 0 --platform "linux/amd64" \ <br/>      --volume "$(pwd)/toolkit-data:/toolkit-data" \ <br/>      --volume "$(pwd)/$TEMPLATES_DIR:/$TEMPLATES_DIR" \ <br/>      --volume "$(pwd)/$TMP_DIR:/$TMP_DIR" \ <br/>      --interactive \ <br/>      "cp.stg.icr.io/cp/concert/toolkit/ibm-concert-toolkit:latest" \ <br/>      bash -c "app-sbom --app-config ${OUTPUT_CONFIG_FILE}" </code> <br/><br/> For the **app-definition** task to function properly, it requires a configuration file containing <a href="https://github.ibm.com/ibm-concert-platinum-demos/concert-pm-utils/blob/64d2bb900519e1eacf06ca275f4f45af2d6263aa/macos/templates/build-sbom-config-template.yaml" target="_blank" rel="noreferrer">this information</a>. |
| **Action** 1.3.4 | In the newly created **data-upload** task of the **post-build-analysis** inner pipeline, include the following commands to create the Concert-defined Build SBOM using the IBM Concert toolkit: <br/><br/> <code class="code-block"> docker run --user 0 --platform "linux/amd64" \ <br/>      --volume "$(pwd)/toolkit-data:/toolkit-data" \ <br/>      --volume "$(pwd)/$TEMPLATES_DIR:/$TEMPLATES_DIR" \ <br/>      --volume "$(pwd)/$TMP_DIR:/$TMP_DIR" \ <br/>      --interactive \ <br/>      "cp.stg.icr.io/cp/concert/toolkit/ibm-concert-toolkit:latest" \ <br/>      bash -c "upload-concert --upload-config ${OUTPUT_DIR}/${DEMO_APP_NAME}-concert-upload-config.yaml" </code> <br/><br/> For the **data-upload** task to function properly, it requires a configuration file containing <a href="https://github.ibm.com/ibm-concert-platinum-demos/concert-pm-utils/blob/64d2bb900519e1eacf06ca275f4f45af2d6263aa/macos/templates/config.yaml" target="_blank" rel="noreferrer">this information</a>. <br/><br/> After the creation of the two new child pipelines described above, the main CI/CD pipeline used for the Proof of Value will be structured as follows: <br/> <img src="images/6.png" width="800" /> |

**[Go to top](#top)**

<br/><br/>

</details>

<p/>

<details markdown="1">

<summary>2 - Onboard application into Concert</summary>

After setting up the shared pipeline infrastructure, you'll need to customize each application previously onboarded by the customer individually. Most CI/CD pipelines have a dedicated property or mapping file where parameters for each application are defined and linked to specific variables within the pipeline. These mappings ensure that each application's configuration is properly aligned with the pipeline's automated tasks.

Typically, the CI/CD server populates these variables automatically using information gathered throughout the pipeline's stages. However, there may be instances where additional customizations will be needed, requiring you to manually define the parameters to ensure proper execution. These manual adjustments often involve setting environment-specific variables or configurations that cannot be dynamically fetched by the server. 

Below is a list of some of the variables that you will need to populate manually:

| **Variable** | **Definition** |
| :--- | :--- |
| **Application criticality** | Refers to the level of importance an application holds within an organization’s IT environment, based on its impact on business operations. <br/><br/> The criticality is rated on a scale of 1 to 5, with: <br/><br/> • **1 (Low criticality)**: Applications that have minimal impact on day-to-day operations. They are not essential for core business functions, and if they go offline, business continuity is not significantly affected. <br/> • **2-3 (Moderate criticality)**: These applications support important business processes but are not mission-critical. Downtime or failure would cause inconvenience and inefficiency but would not disrupt key business operations. <br/> • **4 (High criticality)**: These applications are integral to business processes. Downtime could severely impact productivity, revenue, or customer satisfaction. They require regular monitoring and robust security measures. <br/> • **5 (Critical)**: These are mission-critical applications, essential for the core functioning of the business. Any downtime would have a catastrophic impact on operations, leading to significant financial or reputational loss. These applications often demand high availability, strong security protocols and fast recovery processes. |
| **Access points that make each microservice and their exposure level** | Refers to the endpoints through which each microservice can be accessed, and they play a critical role in determining the exposure level of a microservice within an architecture. Each microservice should ideally have only one access point to maintain clarity and control over how it is accessed and exposed. <br/><br/> These access points can be classified as internal or external based on their exposure: <br/><br/> • **Internal access points**: These are used for communication between services within the organization's internal network or environment. They are not exposed to the internet and are generally accessed only by other microservices or internal systems. This limited exposure reduces the security risks associated with external threats. <br/> • **External access points**: These are exposed to the internet and can be accessed by external users or systems outside of the internal network. External access points require additional security measures, such as authentication, encryption and firewall rules, to protect them from vulnerabilities and unauthorized access. |
| **Environments for each microservice** | Refers to the distinct settings or stages in which a microservice operates, each serving a unique purpose in the development, testing, and deployment lifecycle. A single microservice can have multiple environments, each tailored to specific activities or stages of its development and release. Typically, these environments include: <br/><br/> • **Development environment (Dev)**: This is where the initial coding and testing of the microservice occur. It is used by developers to implement new features, fix bugs, and experiment with changes without affecting the live system. <br/> • **Testing or QA environment**: After development, the microservice moves to a testing environment, where it undergoes more rigorous testing by quality assurance (QA) teams. This environment closely mirrors production to ensure that everything works as expected before deployment. <br/> • **Staging environment**: Staging is a pre-production environment that is nearly identical to the live environment. It’s used to test the entire system, including integrations and performance, to validate that the microservice is ready for release. <br/> • **Production environment**: This is the live environment where the microservice is deployed for actual use by end users. It requires the highest level of monitoring, security and support, as any issues here directly affect the user experience. <br/><br/> Each microservice can have one or more of these environments depending on its development and deployment needs. |
| **Repositories for each microservice** | Dedicated storage locations where the codebase for each microservice is maintained and version-controlled. Each microservice should have its own repository to ensure clear separation of concerns, streamline development and facilitate independent updates and scaling. |

**[Go to top](#top)**

<br/><br/>

</details>